{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple generation of random data (useful to compute the p-value)\n",
    "rand_generations = 100000\n",
    "mult_x = [x for i in range(rand_generations)] # 100000 batches of features\n",
    "mult_y = [np.sin(x) + 0.1*np.power(x,2) + 0.5*np.random.randn(100,1)\n",
    "            for i in range(rand_generations)] # 100000 batches of targets\n",
    "\n",
    "# Recap of optimized parameters (from Pytorch)\n",
    "W = model.weight.item()\n",
    "b = model.bias.item()\n",
    "\n",
    "# Compute multiple MSEs (learned model)\n",
    "mult_y_hat = [mult_x[i].dot(W) + b\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_loss_fit = [mult_y_hat[i] - mult_y[i]\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_mse_fit = [np.sum(np.power(mult_loss_fit[i], 2)) / (2 * n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Compute multiple MSEs (mean model)\n",
    "mult_y_mean = [np.mean(mult_y[i])\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_loss_mean = [mult_y_mean[i] - mult_y[i]\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_mse_mean = [np.sum(np.power(mult_loss_mean[i], 2)) / (2 * n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Compute multiple F\n",
    "mult_f_ratio = [compute_f_ratio(mult_mse_fit[i], mult_mse_mean[i], p_fit, p_mean, n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Plot the multiple F ratios generated from random data\n",
    "plt.figure(figsize=(20,25))\n",
    "\n",
    "# Emphasize the generated F ratio among all generated random data\n",
    "plt.subplot(4,2,1)\n",
    "heights, bins, patches = plt.hist(x=Counter(mult_f_ratio), bins='auto',\n",
    "                            color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n",
    "print(heights)\n",
    "print(bins)\n",
    "\n",
    "idx = (np.abs(bins - f_ratio)).argmin() # Visualization trick: closest F ratio in bins \n",
    "\n",
    "patches[idx].set_fc('#ff8c00')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('F')\n",
    "plt.ylabel('Frequency of F')\n",
    "maxfreq = heights.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10) # Clean upper y-axis limit.\n",
    "\n",
    "# Emphasize the all bars that have a probability equal or less than the compute F ratio\n",
    "# This will show a graphical representation of the p-value\n",
    "plt.subplot(4,2,2)\n",
    "heights, bins, patches = plt.hist(x=mult_f_ratio, bins='auto',\n",
    "                            color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n",
    "idx_p_value = list(np.argwhere(heights < heights[idx]).reshape(-1,))\n",
    "patches[idx].set_fc('#ff8c00') # Coluring f ratio\n",
    "for p in idx_p_value:\n",
    "    patches[p].set_fc('#ffd700') # Coluring f < f ratio\n",
    "\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('F')\n",
    "plt.ylabel('Frequency of F')\n",
    "maxfreq = heights.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10) # Clean upper y-axis limit.\n",
    "\n",
    "# Plot!\n",
    "plt.show()\n",
    "\n",
    "# Recap of number of samples\n",
    "num_samples = np.sum(heights)\n",
    "\n",
    "# p-value is the sum of 3 different probabilities\n",
    "\n",
    "# probability 1\n",
    "p1 = heights[idx] / num_samples # Probability of the sample\n",
    "\n",
    "# probability 2\n",
    "p2 = (heights == heights[idx]).sum() - 1 # Cases with the same probability (excluding the sample)\n",
    "p2 = p2 * heights[idx]\n",
    "p2 = p2 / num_samples # Cases with the same probability of the samples\n",
    "\n",
    "# probability 3\n",
    "idx_p_value = list(np.argwhere(heights < heights[idx]).reshape(-1,)) # Recap of the indices with less probability\n",
    "occurrences = 0\n",
    "for p in idx_p_value:\n",
    "    occurrences += heights[p]\n",
    "p3 = occurrences / num_samples\n",
    "\n",
    "p_value = p1 + p2 + p3\n",
    "\n",
    "print('----- p_value: %.4f\\n' % p_value)\n",
    "print()\n",
    "if p_value < 0.05:  # Setting our significance level at 5%\n",
    "    print('The computed R_squared is statistically relevant.')\n",
    "else:\n",
    "    print('The computed R_squared is not statistically relevant.')\n",
    "\n",
    "\n",
    "https://openclassrooms.com/en/courses/5873596-design-effective-statistical-models-to-understand-your-data/6229141-build-and-interpret-a-univariate-linear-regression-model#:~:text=null%20hypothesis%20anyway.-,R%2DSquared,positive%20and%20lower%20than%201.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid coordinates for plotting\n",
    "B0 = np.linspace(W[0] - 2, W[0] + 2, 50)\n",
    "print(B0)\n",
    "print(B0.size)\n",
    "B1 = np.linspace(W[1] - 2, W[1] + 2, 50)\n",
    "print(B1)\n",
    "print(B1.size)\n",
    "xx, yy = np.meshgrid(B0, B1, indexing='xy')\n",
    "print(xx)\n",
    "print(xx[0])\n",
    "print(xx.shape)\n",
    "print(yy)\n",
    "print(yy[0])\n",
    "print(yy.shape)\n",
    "Z = np.zeros((B0.size, B1.size))\n",
    "print(Z.shape)\n",
    "\n",
    "# Calculate Z-values (MSE) based on grid of parameters\n",
    "for (i, j) , v in np.ndenumerate(Z): # Iterate each element of a multiple array and return the coordinates and the value\n",
    "    Z[i,j] =((y - (xx[i,j] + x*yy[i,j]))**2).sum() / n\n",
    "\n",
    "print(Z)\n",
    "print(Z[25][25])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minimized MSE\n",
    "min_MSE_label = r'$b$, $W$ that minimize the MSE'\n",
    "min_mse = error\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('Mean Squared Error - Regression Parameters', fontsize=20)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "# Left plot\n",
    "CS = ax1.contour(xx, yy, Z, cmap=plt.cm.Set1, levels=[2.2, 2.3, 2.5, 3])\n",
    "ax1.scatter(W[0], W[1], c='r', label=min_MSE_label)\n",
    "ax1.clabel(CS, inline=True, fontsize=10, fmt='%1.1f')\n",
    "\n",
    "# Right plot\n",
    "ax2.plot_surface(xx, yy, Z, rstride=3, cstride=3, alpha=0.3)\n",
    "ax2.contour(xx, yy, Z, zdir='z', offset=Z.min(), cmap=plt.cm.Set1,\n",
    "            alpha=0.4, levels=[2.2, 2.3, 2.5, 3])\n",
    "ax2.scatter3D(W[0], W[1], min_mse, c='r', label=min_MSE_label)\n",
    "ax2.set_zlabel('MSE')\n",
    "ax2.set_zlim(Z.min(),Z.max())\n",
    "ax2.set_ylim(8, 12)\n",
    "\n",
    "# Settings common to both plots\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel(r'$b$', fontsize=14)\n",
    "    ax.set_ylabel(r'$W$', fontsize=14)\n",
    "    ax.set_yticks([W[1]-2, W[1]-1, W[1], W[1]+1, W[1]+2])\n",
    "    ax.set_xticks([W[0]-2, W[0]-1, W[0], W[0]+1, W[0]+2])\n",
    "    ax.legend()\n"
   ]
  }
 ]
}