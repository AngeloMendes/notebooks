{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple generation of random data (useful to compute the p-value)\n",
    "rand_generations = 100000\n",
    "mult_x = [x for i in range(rand_generations)] # 100000 batches of features\n",
    "mult_y = [np.sin(x) + 0.1*np.power(x,2) + 0.5*np.random.randn(100,1)\n",
    "            for i in range(rand_generations)] # 100000 batches of targets\n",
    "\n",
    "# Recap of optimized parameters (from Pytorch)\n",
    "W = model.weight.item()\n",
    "b = model.bias.item()\n",
    "\n",
    "# Compute multiple MSEs (learned model)\n",
    "mult_y_hat = [mult_x[i].dot(W) + b\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_loss_fit = [mult_y_hat[i] - mult_y[i]\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_mse_fit = [np.sum(np.power(mult_loss_fit[i], 2)) / (2 * n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Compute multiple MSEs (mean model)\n",
    "mult_y_mean = [np.mean(mult_y[i])\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_loss_mean = [mult_y_mean[i] - mult_y[i]\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "mult_mse_mean = [np.sum(np.power(mult_loss_mean[i], 2)) / (2 * n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Compute multiple F\n",
    "mult_f_ratio = [compute_f_ratio(mult_mse_fit[i], mult_mse_mean[i], p_fit, p_mean, n)\n",
    "                for i in range(rand_generations)]\n",
    "\n",
    "# Plot the multiple F ratios generated from random data\n",
    "plt.figure(figsize=(20,25))\n",
    "\n",
    "# Emphasize the generated F ratio among all generated random data\n",
    "plt.subplot(4,2,1)\n",
    "heights, bins, patches = plt.hist(x=Counter(mult_f_ratio), bins='auto',\n",
    "                            color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n",
    "print(heights)\n",
    "print(bins)\n",
    "\n",
    "idx = (np.abs(bins - f_ratio)).argmin() # Visualization trick: closest F ratio in bins \n",
    "\n",
    "patches[idx].set_fc('#ff8c00')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('F')\n",
    "plt.ylabel('Frequency of F')\n",
    "maxfreq = heights.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10) # Clean upper y-axis limit.\n",
    "\n",
    "# Emphasize the all bars that have a probability equal or less than the compute F ratio\n",
    "# This will show a graphical representation of the p-value\n",
    "plt.subplot(4,2,2)\n",
    "heights, bins, patches = plt.hist(x=mult_f_ratio, bins='auto',\n",
    "                            color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n",
    "idx_p_value = list(np.argwhere(heights < heights[idx]).reshape(-1,))\n",
    "patches[idx].set_fc('#ff8c00') # Coluring f ratio\n",
    "for p in idx_p_value:\n",
    "    patches[p].set_fc('#ffd700') # Coluring f < f ratio\n",
    "\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('F')\n",
    "plt.ylabel('Frequency of F')\n",
    "maxfreq = heights.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10) # Clean upper y-axis limit.\n",
    "\n",
    "# Plot!\n",
    "plt.show()\n",
    "\n",
    "# Recap of number of samples\n",
    "num_samples = np.sum(heights)\n",
    "\n",
    "# p-value is the sum of 3 different probabilities\n",
    "\n",
    "# probability 1\n",
    "p1 = heights[idx] / num_samples # Probability of the sample\n",
    "\n",
    "# probability 2\n",
    "p2 = (heights == heights[idx]).sum() - 1 # Cases with the same probability (excluding the sample)\n",
    "p2 = p2 * heights[idx]\n",
    "p2 = p2 / num_samples # Cases with the same probability of the samples\n",
    "\n",
    "# probability 3\n",
    "idx_p_value = list(np.argwhere(heights < heights[idx]).reshape(-1,)) # Recap of the indices with less probability\n",
    "occurrences = 0\n",
    "for p in idx_p_value:\n",
    "    occurrences += heights[p]\n",
    "p3 = occurrences / num_samples\n",
    "\n",
    "p_value = p1 + p2 + p3\n",
    "\n",
    "print('----- p_value: %.4f\\n' % p_value)\n",
    "print()\n",
    "if p_value < 0.05:  # Setting our significance level at 5%\n",
    "    print('The computed R_squared is statistically relevant.')\n",
    "else:\n",
    "    print('The computed R_squared is not statistically relevant.')\n",
    "\n",
    "\n",
    "https://openclassrooms.com/en/courses/5873596-design-effective-statistical-models-to-understand-your-data/6229141-build-and-interpret-a-univariate-linear-regression-model#:~:text=null%20hypothesis%20anyway.-,R%2DSquared,positive%20and%20lower%20than%201.\n",
    "\n"
   ]
  }
 ]
}